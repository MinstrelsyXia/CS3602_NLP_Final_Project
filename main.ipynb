{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d30edf2",
   "metadata": {
    "papermill": {
     "duration": 0.003268,
     "end_time": "2024-12-18T03:25:19.850360",
     "exception": false,
     "start_time": "2024-12-18T03:25:19.847092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "安装opencompass：Kaggle上已经为我们准备好了其他常用包，只需安装opencompass用于评测即可。如果不在Kaggle上运行，则还需要安装其他必要包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad5f61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T03:25:19.857025Z",
     "iopub.status.busy": "2024-12-18T03:25:19.856720Z",
     "iopub.status.idle": "2024-12-18T03:26:32.460333Z",
     "shell.execute_reply": "2024-12-18T03:26:32.459518Z"
    },
    "papermill": {
     "duration": 72.609296,
     "end_time": "2024-12-18T03:26:32.462466",
     "exception": false,
     "start_time": "2024-12-18T03:25:19.853170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencompass[full]\n",
      "  Downloading opencompass-0.3.7-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: absl-py in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from opencompass[full]) (2.1.0)\n",
      "Collecting accelerate>=0.19.0 (from opencompass[full])\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting cpm-kernels (from opencompass[full])\n",
      "  Downloading cpm_kernels-1.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: datasets>=2.12.0 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from opencompass[full]) (3.2.0)\n",
      "Collecting einops==0.5.0 (from opencompass[full])\n",
      "  Downloading einops-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting evaluate>=0.3.0 (from opencompass[full])\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting func-timeout (from opencompass[full])\n",
      "  Downloading func_timeout-4.3.5.tar.gz (44 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fuzzywuzzy (from opencompass[full])\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting h5py (from opencompass[full])\n",
      "  Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting huggingface-hub<=0.24.7 (from opencompass[full])\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting immutabledict (from opencompass[full])\n",
      "  Downloading immutabledict-4.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: importlib-metadata in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from opencompass[full]) (8.5.0)\n",
      "Collecting jieba (from opencompass[full])\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting json5 (from opencompass[full])\n",
      "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting mmengine-lite (from opencompass[full])\n",
      "  Downloading mmengine_lite-0.10.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting nltk==3.8 (from opencompass[full])\n",
      "  Downloading nltk-3.8-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.4 (from opencompass[full])\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting openai (from opencompass[full])\n",
      "  Downloading openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting OpenCC (from opencompass[full])\n",
      "  Downloading OpenCC-1.1.9-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting opencv-python-headless (from opencompass[full])\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting pandas<2.0.0 (from opencompass[full])\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting prettytable (from opencompass[full])\n",
      "  Downloading prettytable-3.12.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: protobuf in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from opencompass[full]) (4.25.3)\n",
      "Collecting pyext (from opencompass[full])\n",
      "  Downloading pyext-0.7.tar.gz (7.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python-Levenshtein (from opencompass[full])\n",
      "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting rank-bm25==0.2.2 (from opencompass[full])\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting rapidfuzz (from opencompass[full])\n",
      "  Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from opencompass[full]) (2.32.3)\n",
      "Collecting retrying (from opencompass[full])\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting rich (from opencompass[full])\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rouge (from opencompass[full])\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting rouge-chinese (from opencompass[full])\n",
      "  Downloading rouge_chinese-1.0.3-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting rouge-score (from opencompass[full])\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu (from opencompass[full])\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting scikit-learn==1.5.0 (from opencompass[full])\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn (from opencompass[full])\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting sentence-transformers==2.2.2 (from opencompass[full])\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from opencompass[full]) (0.9.0)\n",
      "Collecting tiktoken (from opencompass[full])\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting timeout-decorator (from opencompass[full])\n",
      "  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.3 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from opencompass[full]) (0.21.0)\n",
      "Requirement already satisfied: torch>=1.13.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from opencompass[full]) (2.5.1)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from opencompass[full]) (4.67.1)\n",
      "Requirement already satisfied: transformers>=4.29.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from opencompass[full]) (4.47.1)\n",
      "Collecting typer (from opencompass[full])\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting alpaca-eval==0.6 (from opencompass[full])\n",
      "  Downloading alpaca_eval-0.6-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting cn2an (from opencompass[full])\n",
      "  Downloading cn2an-0.5.23-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting dingo-python==1.1.2 (from opencompass[full])\n",
      "  Downloading dingo_python-1.1.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting faiss-gpu==1.7.2 (from opencompass[full])\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting human-eval (from opencompass[full])\n",
      "  Downloading human_eval-1.0.3-py3-none-any.whl.metadata (153 bytes)\n",
      "Collecting langdetect (from opencompass[full])\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting latex2sympy2 (from opencompass[full])\n",
      "  Downloading latex2sympy2-1.9.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting ltp (from opencompass[full])\n",
      "  Downloading ltp-4.2.14-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pypinyin (from opencompass[full])\n",
      "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting wonderwords (from opencompass[full])\n",
      "  Downloading wonderwords-2.2.0-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting python-dotenv (from alpaca-eval==0.6->opencompass[full])\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting fire (from alpaca-eval==0.6->opencompass[full])\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from alpaca-eval==0.6->opencompass[full]) (1.14.1)\n",
      "Collecting patsy (from alpaca-eval==0.6->opencompass[full])\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting boto3==1.28.43 (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading boto3-1.28.43-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore==1.31.43 (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading botocore-1.31.43-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: chardet in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from dingo-python==1.1.2->opencompass[full]) (5.2.0)\n",
      "Collecting fasttext-wheel==0.9.2 (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting hanziconv (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading hanziconv-0.3.2.tar.gz (276 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jsonlines (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langid (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from dingo-python==1.1.2->opencompass[full]) (4.10.0.84)\n",
      "Requirement already satisfied: packaging in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from dingo-python==1.1.2->opencompass[full]) (24.2)\n",
      "Collecting Pillow==9.4.0 (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading Pillow-9.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pydantic in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from dingo-python==1.1.2->opencompass[full]) (2.10.4)\n",
      "Collecting textstat (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting toml (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting wordninja==2.0.0 (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.6/541.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting zhon (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading zhon-2.1.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting fastapi (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn (from dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: click in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from nltk==3.8->opencompass[full]) (8.1.7)\n",
      "Requirement already satisfied: joblib in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from nltk==3.8->opencompass[full]) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from nltk==3.8->opencompass[full]) (2024.11.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from scikit-learn==1.5.0->opencompass[full]) (3.5.0)\n",
      "Requirement already satisfied: torchvision in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from sentence-transformers==2.2.2->opencompass[full]) (0.20.1)\n",
      "Collecting sentencepiece (from sentence-transformers==2.2.2->opencompass[full])\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3==1.28.43->dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3==1.28.43->dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading s3transfer-0.6.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from botocore==1.31.43->dingo-python==1.1.2->opencompass[full]) (2.9.0.post0)\n",
      "Collecting urllib3<1.27,>=1.25.4 (from botocore==1.31.43->dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting pybind11>=2.2 (from fasttext-wheel==0.9.2->dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from fasttext-wheel==0.9.2->dingo-python==1.1.2->opencompass[full]) (75.1.0)\n",
      "Requirement already satisfied: psutil in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from accelerate>=0.19.0->opencompass[full]) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from accelerate>=0.19.0->opencompass[full]) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from accelerate>=0.19.0->opencompass[full]) (0.4.5)\n",
      "Requirement already satisfied: filelock in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from datasets>=2.12.0->opencompass[full]) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from datasets>=2.12.0->opencompass[full]) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from datasets>=2.12.0->opencompass[full]) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from datasets>=2.12.0->opencompass[full]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from datasets>=2.12.0->opencompass[full]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.12.0->opencompass[full]) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from datasets>=2.12.0->opencompass[full]) (3.11.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from huggingface-hub<=0.24.7->opencompass[full]) (4.12.2)\n",
      "Collecting anyio<5,>=3.5.0 (from openai->opencompass[full])\n",
      "  Downloading anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->opencompass[full])\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->opencompass[full])\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai->opencompass[full])\n",
      "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai->opencompass[full])\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from pandas<2.0.0->opencompass[full]) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from requests>=2.31.0->opencompass[full]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from requests>=2.31.0->opencompass[full]) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from requests>=2.31.0->opencompass[full]) (2024.12.14)\n",
      "Requirement already satisfied: networkx in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from torch>=1.13.1->opencompass[full]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.1->opencompass[full]) (1.3.0)\n",
      "Collecting proces>=0.1.7 (from cn2an->opencompass[full])\n",
      "  Downloading proces-0.1.7-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from importlib-metadata->opencompass[full]) (3.21.0)\n",
      "Requirement already satisfied: six in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from langdetect->opencompass[full]) (1.17.0)\n",
      "Collecting antlr4-python3-runtime==4.7.2 (from latex2sympy2->opencompass[full])\n",
      "  Downloading antlr4-python3-runtime-4.7.2.tar.gz (112 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ltp-core>=0.1.3 (from ltp->opencompass[full])\n",
      "  Downloading ltp_core-0.1.4-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting ltp-extension>=0.1.9 (from ltp->opencompass[full])\n",
      "  Downloading ltp_extension-0.1.13-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: addict in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from mmengine-lite->opencompass[full]) (2.4.0)\n",
      "Requirement already satisfied: termcolor in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from mmengine-lite->opencompass[full]) (2.5.0)\n",
      "Requirement already satisfied: yapf in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from mmengine-lite->opencompass[full]) (0.43.0)\n",
      "Requirement already satisfied: wcwidth in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from prettytable->opencompass[full]) (0.2.13)\n",
      "Collecting Levenshtein==0.26.1 (from python-Levenshtein->opencompass[full])\n",
      "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->opencompass[full])\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from rich->opencompass[full]) (2.18.0)\n",
      "Requirement already satisfied: portalocker in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from sacrebleu->opencompass[full]) (3.0.0)\n",
      "Collecting colorama (from sacrebleu->opencompass[full])\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lxml (from sacrebleu->opencompass[full])\n",
      "  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from seaborn->opencompass[full]) (3.10.0)\n",
      "Collecting shellingham>=1.3.0 (from typer->opencompass[full])\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->opencompass[full]) (1.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.12.0->opencompass[full]) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.12.0->opencompass[full]) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.12.0->opencompass[full]) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.12.0->opencompass[full]) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.12.0->opencompass[full]) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.12.0->opencompass[full]) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.12.0->opencompass[full]) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.12.0->opencompass[full]) (1.18.3)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->opencompass[full])\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->opencompass[full])\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "\u001b[33mWARNING: Package 'ltp-core' has an invalid Requires-Python: Invalid specifier: '>=3.6.*'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->opencompass[full])\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->opencompass[full]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->opencompass[full]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->opencompass[full]) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->opencompass[full]) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->opencompass[full]) (3.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from pydantic->dingo-python==1.1.2->opencompass[full]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/xiaxinyuan/.local/lib/python3.10/site-packages (from pydantic->dingo-python==1.1.2->opencompass[full]) (2.27.2)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi->dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from jinja2->torch>=1.13.1->opencompass[full]) (3.0.2)\n",
      "Collecting pyphen (from textstat->dingo-python==1.1.2->opencompass[full])\n",
      "  Downloading pyphen-0.17.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from yapf->mmengine-lite->opencompass[full]) (4.3.6)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /g0433_data/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages (from yapf->mmengine-lite->opencompass[full]) (2.2.1)\n",
      "Downloading alpaca_eval-0.6-py3-none-any.whl (283 kB)\n",
      "Downloading dingo_python-1.1.2-py3-none-any.whl (73 kB)\n",
      "Downloading einops-0.5.0-py3-none-any.whl (36 kB)\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.28.43-py3-none-any.whl (135 kB)\n",
      "Downloading botocore-1.31.43-py3-none-any.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Pillow-9.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
      "Downloading openai-1.58.1-py3-none-any.whl (454 kB)\n",
      "Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cn2an-0.5.23-py3-none-any.whl (224 kB)\n",
      "Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading human_eval-1.0.3-py3-none-any.whl (52 kB)\n",
      "Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
      "Downloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
      "Downloading latex2sympy2-1.9.1-py3-none-any.whl (89 kB)\n",
      "Downloading ltp-4.2.14-py3-none-any.whl (20 kB)\n",
      "Downloading mmengine_lite-0.10.5-py3-none-any.whl (452 kB)\n",
      "Downloading OpenCC-1.1.9-cp310-cp310-manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencompass-0.3.7-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading prettytable-3.12.0-py3-none-any.whl (31 kB)\n",
      "Downloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
      "Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
      "Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading wonderwords-2.2.0-py3-none-any.whl (44 kB)\n",
      "Downloading anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Downloading ltp_core-0.1.4-py3-none-any.whl (66 kB)\n",
      "Downloading ltp_extension-0.1.13-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading proces-0.1.7-py3-none-any.whl (137 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading textstat-0.7.4-py3-none-any.whl (105 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading zhon-2.1.1-py3-none-any.whl (83 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "Downloading s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Downloading pyphen-0.17.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence-transformers, wordninja, func-timeout, jieba, langdetect, antlr4-python3-runtime, pyext, rouge-score, timeout-decorator, fire, hanziconv, langid\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=9c3f6788e7137362397236205d7138505501a83153d88a6c098c4de6f54f4df4\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "  Building wheel for wordninja (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541530 sha256=138b9c206ae75f55f1441b4eecf47dd2050f4364b6676eb54b1e3aeb1910dba6\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/aa/44/3a/f2a5c1859b8b541ded969b4cd12d0a58897f12408f4f51e084\n",
      "  Building wheel for func-timeout (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for func-timeout: filename=func_timeout-4.3.5-py3-none-any.whl size=15076 sha256=06a52f5a981fdc0432e0bac943f2a9d34da83545500f4f1dd06d14999e6d862d\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/3f/83/19/b5552bb9630e353f7c5b15be44bf10900afe1abbbfcf536afd\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=fdca7bda095e25f4fa4e4da2937a2c1e702424984aac533c14227f1efd00fa55\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/c9/69/31/d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=bb8d0614daa9dedd7867bea6e4a4383ab9d488105a651b3b9711a83acf2efe26\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.7.2-py3-none-any.whl size=140931 sha256=36eb3bf96c4e300fbf0e63375f22925ad438380f00786a82ccff3b6b3d4d5c75\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/79/20/ec/30bf7dabc29319ccc0d0c96f910a640513a3c81faa960fed43\n",
      "  Building wheel for pyext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyext: filename=pyext-0.7-py3-none-any.whl size=7222 sha256=bbb114461844399050e1170eaf40035c08f3528a1e56719b0ab59e2bd3794e84\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/09/95/a9/f3f15c5e52dec7912c332ae503e82fd680e576bf336437f002\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=8bc1172277661806ac41da3f03af0f5536bc4de59d31628800a6dc6561352095\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for timeout-decorator: filename=timeout_decorator-0.5.0-py3-none-any.whl size=5007 sha256=a71767a599546de5dbd259b97e26c7c38469e6fbb70e37eb2965344aa1a63c65\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/68/2f/bc/76f1192d474666d41ae6f09813fccbd00fe3f07e8261c4cff5\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=55c9aa231a85fd0797187ef4924e1b54900168470f0a746da521f40be4fc27f1\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
      "  Building wheel for hanziconv (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hanziconv: filename=hanziconv-0.3.2-py2.py3-none-any.whl size=23209 sha256=980d2f9dd7565877eae644c6dc04808200369c2659640dd6ad486d793849f6a3\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/62/5a/e5/779585d31b977c0fa445b649a256d1fae60728fdc21c1373dc\n",
      "  Building wheel for langid (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941171 sha256=9d1ea2cda8e5fa6a4bc00064e52123e2bf393216fcb03a551d75713a0b40d79d\n",
      "  Stored in directory: /home/xiaxinyuan/.cache/pip/wheels/23/c8/c6/eed80894918490a175677414d40bd7c851413bbe03d4856c3c\n",
      "Successfully built sentence-transformers wordninja func-timeout jieba langdetect antlr4-python3-runtime pyext rouge-score timeout-decorator fire hanziconv langid\n",
      "Installing collected packages: wordninja, timeout-decorator, sentencepiece, pyext, OpenCC, ltp-extension, jieba, hanziconv, fuzzywuzzy, func-timeout, faiss-gpu, cpm-kernels, antlr4-python3-runtime, zhon, wonderwords, urllib3, toml, sniffio, shellingham, rouge-chinese, rouge, retrying, rapidfuzz, python-dotenv, pypinyin, pyphen, pybind11, proces, prettytable, Pillow, numpy, nltk, mdurl, lxml, langdetect, jsonlines, json5, jmespath, jiter, immutabledict, h11, fire, einops, distro, colorama, uvicorn, textstat, sacrebleu, rouge-score, rank-bm25, patsy, pandas, opencv-python-headless, markdown-it-py, Levenshtein, latex2sympy2, langid, human-eval, httpcore, h5py, fasttext-wheel, cn2an, botocore, anyio, tiktoken, starlette, scikit-learn, s3transfer, rich, python-Levenshtein, huggingface-hub, httpx, typer, seaborn, openai, mmengine-lite, fastapi, boto3, accelerate, sentence-transformers, ltp-core, evaluate, dingo-python, alpaca-eval, opencompass, ltp\n",
      "  Attempting uninstall: einops\n",
      "    Found existing installation: einops 0.8.0\n",
      "    Uninstalling einops-0.8.0:\n",
      "      Successfully uninstalled einops-0.8.0\n",
      "Successfully installed Levenshtein-0.26.1 OpenCC-1.1.9 Pillow-9.4.0 accelerate-1.2.1 alpaca-eval-0.6 antlr4-python3-runtime-4.7.2 anyio-4.7.0 boto3-1.28.43 botocore-1.31.43 cn2an-0.5.23 colorama-0.4.6 cpm-kernels-1.0.11 dingo-python-1.1.2 distro-1.9.0 einops-0.5.0 evaluate-0.4.3 faiss-gpu-1.7.2 fastapi-0.115.6 fasttext-wheel-0.9.2 fire-0.7.0 func-timeout-4.3.5 fuzzywuzzy-0.18.0 h11-0.14.0 h5py-3.12.1 hanziconv-0.3.2 httpcore-1.0.7 httpx-0.28.1 huggingface-hub-0.24.7 human-eval-1.0.3 immutabledict-4.2.1 jieba-0.42.1 jiter-0.8.2 jmespath-1.0.1 json5-0.10.0 jsonlines-4.0.0 langdetect-1.0.9 langid-1.1.6 latex2sympy2-1.9.1 ltp-4.2.14 ltp-core-0.1.4 ltp-extension-0.1.13 lxml-5.3.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmengine-lite-0.10.5 nltk-3.8 numpy-1.26.4 openai-1.58.1 opencompass-0.3.7 opencv-python-headless-4.10.0.84 pandas-1.5.3 patsy-1.0.1 prettytable-3.12.0 proces-0.1.7 pybind11-2.13.6 pyext-0.7 pyphen-0.17.0 pypinyin-0.53.0 python-Levenshtein-0.26.1 python-dotenv-1.0.1 rank-bm25-0.2.2 rapidfuzz-3.11.0 retrying-1.3.4 rich-13.9.4 rouge-1.0.1 rouge-chinese-1.0.3 rouge-score-0.1.2 s3transfer-0.6.2 sacrebleu-2.4.3 scikit-learn-1.5.0 seaborn-0.13.2 sentence-transformers-2.2.2 sentencepiece-0.2.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.41.3 textstat-0.7.4 tiktoken-0.8.0 timeout-decorator-0.5.0 toml-0.10.2 typer-0.15.1 urllib3-1.26.20 uvicorn-0.34.0 wonderwords-2.2.0 wordninja-2.0.0 zhon-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install \"opencompass[full]\"\n",
    "# !pip install pytorch transformers datasets \"opencompass[full]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fa097e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T03:26:32.491641Z",
     "iopub.status.busy": "2024-12-18T03:26:32.491352Z",
     "iopub.status.idle": "2024-12-18T03:26:32.494975Z",
     "shell.execute_reply": "2024-12-18T03:26:32.494354Z"
    },
    "papermill": {
     "duration": 0.020026,
     "end_time": "2024-12-18T03:26:32.496539",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.476513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchar-lotte\u001b[0m (\u001b[33mchar-lotte-xia\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/xiaxinyuan/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"xxx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba38acc",
   "metadata": {
    "papermill": {
     "duration": 0.012835,
     "end_time": "2024-12-18T03:26:32.522445",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.509610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 指令微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae351b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T03:26:32.550041Z",
     "iopub.status.busy": "2024-12-18T03:26:32.549781Z",
     "iopub.status.idle": "2024-12-18T03:26:32.556950Z",
     "shell.execute_reply": "2024-12-18T03:26:32.556095Z"
    },
    "papermill": {
     "duration": 0.023187,
     "end_time": "2024-12-18T03:26:32.558517",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.535330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaxinyuan/.conda/envs/dino/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The main program for finetuning LLMs with Huggingface Transformers Library.\n",
    "\n",
    "ALL SECTIONS WHERE CODE POSSIBLY NEEDS TO BE FILLED IN ARE MARKED AS TODO.\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List, Dict\n",
    "import sys\n",
    "import torch\n",
    "from transformers import TrainingArguments, HfArgumentParser, Trainer, AutoTokenizer, AutoModelForCausalLM\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538a80a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T03:26:32.585208Z",
     "iopub.status.busy": "2024-12-18T03:26:32.584943Z",
     "iopub.status.idle": "2024-12-18T03:26:32.588763Z",
     "shell.execute_reply": "2024-12-18T03:26:32.588121Z"
    },
    "papermill": {
     "duration": 0.018959,
     "end_time": "2024-12-18T03:26:32.590324",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.571365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the arguments required for the main program.\n",
    "# NOTE: You can customize any arguments you need to pass in.\n",
    "# @dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"Arguments for model\n",
    "    \"\"\"\n",
    "    model_name_or_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The path to the LLM to fine-tune or its name on the Hugging Face Hub.\"\n",
    "        }\n",
    "    )\n",
    "    torch_dtype: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Override the default `torch.dtype` and load the model under this dtype.\"\n",
    "            ),\n",
    "            \"choices\": [\"bfloat16\", \"float16\", \"float32\"],\n",
    "        },\n",
    "    )\n",
    "    # TODO: add your model arguments here\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataArguments:\n",
    "    \"\"\"Arguments for data\n",
    "    \"\"\"\n",
    "    dataset_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The path to the fine-tuning dataset or its name on the Hugging Face Hub.\"\n",
    "        }\n",
    "    )\n",
    "    # TODO: add your data arguments here\n",
    "    max_length: int = field(\n",
    "        default=512,\n",
    "        metadata={\n",
    "            \"help\": \"The max length of tokenized data.\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a52946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T03:26:32.618003Z",
     "iopub.status.busy": "2024-12-18T03:26:32.617774Z",
     "iopub.status.idle": "2024-12-18T03:26:32.624308Z",
     "shell.execute_reply": "2024-12-18T03:26:32.623600Z"
    },
    "papermill": {
     "duration": 0.02235,
     "end_time": "2024-12-18T03:26:32.625846",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.603496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The main function\n",
    "# NOTE You can customize some logs to monitor your program.\n",
    "def finetune():\n",
    "    # TODO Step 1: Define an arguments parser and parse the arguments\n",
    "    # NOTE Three parts: model arguments, data arguments, and training arguments\n",
    "    # HINT: Refer to \n",
    "    #   * https://huggingface.co/docs/transformers/v4.46.3/en/internal/trainer_utils#transformers.HfArgumentParser\n",
    "    #   * https://huggingface.co/docs/transformers/v4.46.3/en/main_classes/trainer#transformers.TrainingArguments\n",
    "    # parser = ...\n",
    "    # model_args, data_args, training_args = ...\n",
    "    ### cjy\n",
    "    parser = HfArgumentParser((ModelArguments, DataArguments, TrainingArguments)) \n",
    "    \"\"\"\n",
    "    hugging face argument parser\n",
    "    \"\"\"\n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "    \"\"\"\n",
    "    return tuple\n",
    "    DataClass 实例的顺序与传递给 initializer.abspath 的顺序相同\n",
    "    如果适用，将更多（非 DataClass 支持的）参数的附加命名空间添加到解析器 初始化后。\n",
    "    剩余参数字符串的可能列表。（与 argparse 相同。ArgumentParser.parse_known_args）\n",
    "    \"\"\"\n",
    "    ### cjy\n",
    "\n",
    "    # TODO Step 2: Load tokenizer and model\n",
    "    # HINT 1: Refer to\n",
    "    #   * https://huggingface.co/docs/transformers/v4.46.3/en/main_classes/tokenizer#tokenizer\n",
    "    #   * https://huggingface.co/docs/transformers/v4.46.3/en/model_doc/qwen2\n",
    "    # HINT 2: To save training GPU memory, you need to set the model's parameter precision to half-precision (float16 or bfloat16).\n",
    "    #         You may also check other strategies to save the memory!\n",
    "    #   * https://huggingface.co/docs/transformers/v4.46.3/en/model_doc/llama2#usage-tips\n",
    "    #   * https://huggingface.co/docs/transformers/perf_train_gpu_one\n",
    "    #   * https://www.53ai.com/news/qianyanjishu/2024052494875.html\n",
    "    # tokenizer = ...\n",
    "    # model = ...\n",
    "    ## cjy\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_args.model_name_or_path)\n",
    "    \"\"\"\n",
    "    从预训练模型的 tokenizer 配置中加载 tokenizer 的配置\n",
    "    input:\n",
    "        pretrained_model_name_or_path: 预训练模型的名称或路径（tokenizer 配置文件 所在的目录 即“Qwen2.5-0.5B”）\n",
    "    功能:\n",
    "        1 函数首先尝试从指定的模型名称或路径加载 tokenizer 配置文件\n",
    "        2 如果找不到配置文件，则从模型库中加载默认的 tokenizer 配置\n",
    "    \"\"\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_args.model_name_or_path, \n",
    "        torch_dtype=model_args.torch_dtype,\n",
    "        trust_remote_code=True,  # Qwen模型需要这个参数\n",
    "        device_map=\"auto\"  # 可选，用于自动处理模型加载到设备\n",
    "    )\n",
    "    \"\"\"\n",
    "    用于从预训练模型加载模型实例。 \n",
    "    \"\"\"\n",
    "    ### cjy\n",
    "\n",
    "    # TODO Step 3: Load dataset\n",
    "    # HINT: https://huggingface.co/docs/datasets/v3.1.0/en/package_reference/main_classes#datasets.Dataset\n",
    "    # dataset = ...\n",
    "    ### cjy\n",
    "    dataset = datasets.load_dataset(path='csv', data_files=data_args.dataset_path)\n",
    "    ### cjy\n",
    "\n",
    "    # TODO Step 4: Define the data collator function\n",
    "    # NOTE During training, for each model parameter update, we fetch a batch of data, perform a forward and backward pass,\n",
    "    # and then update the model parameters. The role of the data collator is to process the data (e.g., padding the data within\n",
    "    # a batch to the same length) and format the batch into the input required by the model.\n",
    "    # 数据整理器（data collator）函数。这个函数的主要任务是处理从数据集中加载的每个数据批次，使其符合模型所需的输入格式\n",
    "    # In this assignment, the purpose of the custom data_collator is to process each batch of data from the dataset loaded in\n",
    "    # Step 3 into the format required by the model. This includes tasks such as tokenizing the data, converting each token into \n",
    "    # an ID sequence, applying padding, and preparing labels.\n",
    "    # 对数据进行标记化（tokenization）。将每个标记转换为 ID 序列。填充（padding），确保批次中的所有数据具有相同的长度。准备标签（labels），以便在训练过程中使用\n",
    "    # HINT:\n",
    "    #   * Before implementation, you should:\n",
    "    #      1. Clearly understand the format of each sample in the dataset loaded in Step 3.\n",
    "    #      2. Understand the input format required by the model (https://huggingface.co/docs/transformers/model_doc/qwen2#transformers.Qwen2ForCausalLM).\n",
    "    #         Reading its source code also helps!\n",
    "\n",
    "    def data_collator(batch: List[Dict]):\n",
    "        \"\"\"\n",
    "        batch: list of dict, each dict of the list is a sample in the dataset.\n",
    "        \"\"\"\n",
    "        # pass\n",
    "        ### cjy\n",
    "        # 期望字典输出\n",
    "        new_batch = {\n",
    "            \"input_ids\": [], #  (torch.LongTensor of shape (batch_size, sequence_length)) \n",
    "            # input ids: 通常是作为输入传递给模型的唯一必需参数. token(模型输入)的数字化表示. https://huggingface.co/docs/transformers/glossary#input-ids\n",
    "            # 用 PreTrainedTokenizer.encode() 方法得到\n",
    "            \"labels\": [] #  (torch.LongTensor of shape (batch_size, sequence_length))\n",
    "            # labels: 标签是模型训练的目标值，用于计算损失函数。 (loss, optional, returned when labels is provided))\n",
    "            # 用 PreTrainedTokenizer.encode() 方法得到 \n",
    "        }\n",
    "        for sample in batch:\n",
    "            new_batch[\"input_ids\"].append(tokenizer.encode(\"instruction:\"+sample[\"instruction\"] if sample[\"instruction\"] else \"\" + \"\\n input:\"+ sample[\"input\"] if sample[\"input\"] else \"\", padding='max_length', max_length=data_args.max_length, truncation=True))\n",
    "            # padding,max_length,truncation: 用于处理输入序列长度不一致的问题。\n",
    "            new_batch[\"labels\"].append(tokenizer.encode(sample[\"output\"],padding='max_length',  max_length=data_args.max_length, truncation=True))\n",
    "        new_batch[\"input_ids\"] = torch.tensor(new_batch[\"input_ids\"])\n",
    "        new_batch[\"labels\"] = torch.tensor(new_batch[\"labels\"])\n",
    "        return new_batch\n",
    "        ### cjy\n",
    "\n",
    "    # TODO Step 5: Define the Trainer\n",
    "    # HINT: https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "    trainer = Trainer(\n",
    "        # ...,\n",
    "        # model=model,\n",
    "        ### cjy\n",
    "        model=model, # 模型  (PreTrainedModel or torch.nn.Module)\n",
    "        args=training_args, # 训练参数 (TrainingArguments)\n",
    "        data_collator=data_collator, # 数据整理器 (DataCollator)\n",
    "        train_dataset=dataset['train'], # 训练数据集 (Dataset)\n",
    "        ### cjy\n",
    "    )\n",
    "\n",
    "    # Step 6: Train!\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b336ae50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T03:26:32.652445Z",
     "iopub.status.busy": "2024-12-18T03:26:32.652189Z",
     "iopub.status.idle": "2024-12-18T03:26:32.655954Z",
     "shell.execute_reply": "2024-12-18T03:26:32.655355Z"
    },
    "papermill": {
     "duration": 0.01872,
     "end_time": "2024-12-18T03:26:32.657539",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.638819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be called with a dataclass type or instance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Pass your training arguments.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# NOTE [IMPORTANT!!!] DO NOT FORGET TO PASS PROPER ARGUMENTS TO SAVE YOUR CHECKPOINTS!!!\u001b[39;00m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# \"--arg1\", \"value1\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--save_total_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m ]\n\u001b[0;32m---> 21\u001b[0m \u001b[43mfinetune\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36mfinetune\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinetune\u001b[39m():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# TODO Step 1: Define an arguments parser and parse the arguments\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# NOTE Three parts: model arguments, data arguments, and training arguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# model_args, data_args, training_args = ...\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m### cjy\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     parser \u001b[38;5;241m=\u001b[39m \u001b[43mHfArgumentParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModelArguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataArguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrainingArguments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    hugging face argument parser\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     model_args, data_args, training_args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args_into_dataclasses()\n",
      "File \u001b[0;32m~/.conda/envs/dino/lib/python3.10/site-packages/transformers/hf_argparser.py:137\u001b[0m, in \u001b[0;36mHfArgumentParser.__init__\u001b[0;34m(self, dataclass_types, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataclass_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dataclass_types)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataclass_types:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_dataclass_arguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dino/lib/python3.10/site-packages/transformers/hf_argparser.py:273\u001b[0m, in \u001b[0;36mHfArgumentParser._add_dataclass_arguments\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    264\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType resolution failed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on Python \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpython_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Try removing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline of `from __future__ import annotations` which opts in union types as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`X | None`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataclasses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field\u001b[38;5;241m.\u001b[39minit:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dino/lib/python3.10/dataclasses.py:1198\u001b[0m, in \u001b[0;36mfields\u001b[0;34m(class_or_instance)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(class_or_instance, _FIELDS)\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m-> 1198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust be called with a dataclass type or instance\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;66;03m# Exclude pseudo-fields.  Note that fields is sorted by insertion\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# order, so the order of the tuple is as the fields were defined.\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_field_type \u001b[38;5;129;01mis\u001b[39;00m _FIELD)\n",
      "\u001b[0;31mTypeError\u001b[0m: must be called with a dataclass type or instance"
     ]
    }
   ],
   "source": [
    "# Pass your training arguments.\n",
    "# NOTE [IMPORTANT!!!] DO NOT FORGET TO PASS PROPER ARGUMENTS TO SAVE YOUR CHECKPOINTS!!!\n",
    "sys.argv = [\n",
    "    \"notebook\", \n",
    "    # \"--arg1\", \"value1\",\n",
    "    # \"--arg2\", \"value2\",\n",
    "    # ...\n",
    "    ### cjy\n",
    "    \"--model_name_or_path\", \"/kaggle/input/qwen2.5/transformers/0.5b/1\",\n",
    "    \"--dataset_path\", \"/kaggle/input/alpaca-language-instruction-training/train.csv\",\n",
    "    \"--torch_dtype\", \"bfloat16\", #see Qwen2.5-0.5B/config.json?\n",
    "    \"--output_dir\", \"/kaggle/working/output/\", # --output_dir 参数在 TrainingArguments 中有\n",
    "    \"--remove_unused_columns\", \"False\", #ValueError: No columns in the dataset match the model's forward method signature. The following columns have been ignored: [output, instruction, input]. Please check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`\n",
    "    \"--max_length\", \"256\",\n",
    "    ### cjy\n",
    "    \"--per_device_train_batch_size\", \"8\",  # 设置训练的 batch size\n",
    "    \"--per_device_eval_batch_size\", \"8\", \n",
    "    \"--save_steps\", \"1000\",\n",
    "    \"--save_total_limit\", \"4\",\n",
    "]\n",
    "finetune()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e945eb",
   "metadata": {
    "papermill": {
     "duration": 0.012698,
     "end_time": "2024-12-18T03:26:32.682982",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.670284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 评测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cc009a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T03:26:32.709630Z",
     "iopub.status.busy": "2024-12-18T03:26:32.709396Z",
     "iopub.status.idle": "2024-12-18T03:26:32.712929Z",
     "shell.execute_reply": "2024-12-18T03:26:32.712232Z"
    },
    "papermill": {
     "duration": 0.018727,
     "end_time": "2024-12-18T03:26:32.714533",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.695806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PLM_MODEL_PATH = \"/kaggle/input/qwen2.5/transformers/0.5b/1\"\n",
    "SFT_MODEL_PATH = \"/kaggle/input/qwen_checkpoint_14000/transformers/default/1/checkpoint_14000\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd6e84",
   "metadata": {
    "papermill": {
     "duration": 0.012672,
     "end_time": "2024-12-18T03:26:32.740120",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.727448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "如果你有多个GPU，可以修改下面的--hf-num-gpus参数来加速评测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28d13fa",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-18T03:26:32.766357Z",
     "iopub.status.busy": "2024-12-18T03:26:32.766113Z",
     "iopub.status.idle": "2024-12-18T03:26:32.769385Z",
     "shell.execute_reply": "2024-12-18T03:26:32.768759Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.018163,
     "end_time": "2024-12-18T03:26:32.770889",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.752726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !opencompass \\\n",
    "#     --datasets mmlu_ppl hellaswag_clean_ppl winogrande_ll ARC_e_ppl ARC_c_clean_ppl SuperGLUE_BoolQ_few_shot_ppl \\\n",
    "#     --summarizer example \\\n",
    "#     --hf-type base \\\n",
    "#     --hf-path {PLM_MODEL_PATH} \\\n",
    "#     --tokenizer-kwargs padding_side=\"left\" truncation=\"left\" \\\n",
    "#     --max-seq-len 2048 \\\n",
    "#     --batch-size 4 \\\n",
    "#     --hf-num-gpus 2 \\\n",
    "#     --work-dir \"/kaggle/working/evals/plm\" \\\n",
    "#     --debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4656f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T03:26:32.797220Z",
     "iopub.status.busy": "2024-12-18T03:26:32.796968Z",
     "iopub.status.idle": "2024-12-18T04:40:39.032354Z",
     "shell.execute_reply": "2024-12-18T04:40:39.031335Z"
    },
    "papermill": {
     "duration": 4446.250972,
     "end_time": "2024-12-18T04:40:39.034445",
     "exception": false,
     "start_time": "2024-12-18T03:26:32.783473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/opencompass/__init__.py:19: UserWarning: Starting from v0.4.0, all AMOTIC configuration files currently located in `./configs/datasets`, `./configs/models`, and `./configs/summarizers` will be migrated to the `opencompass/configs/` package. Please update your configuration file paths accordingly.\r\n",
      "  _warn_about_config_migration()\r\n",
      "12/18 03:27:09 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Loading mmlu_ppl: /opt/conda/lib/python3.10/site-packages/opencompass/configs/./datasets/mmlu/mmlu_ppl.py\r\n",
      "12/18 03:27:09 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Loading example: /opt/conda/lib/python3.10/site-packages/opencompass/configs/./summarizers/example.py\r\n",
      "12/18 03:27:09 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Current exp folder: /kaggle/working/evals/sft/20241218_032709\r\n",
      "12/18 03:27:09 - OpenCompass - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - SlurmRunner is not used, so the partition argument is ignored.\r\n",
      "12/18 03:27:09 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - ./data/mmlu/ does not exist!Start Download data automatically!If you have downloaded the data before,You can specific `COMPASS_DATA_CACHE` to avoid downloading~\r\n",
      "Downloading http://opencompass.oss-cn-shanghai.aliyuncs.com/datasets/data/mmlu.zip to /root/.cache/opencompass/data/mmlu.zip\r\n",
      "\u001b[2K\u001b[32m2.5/2.5 MB\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hExtracting /root/.cache/opencompass/data/mmlu.zip to /root/.cache/opencompass/data\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Try to load the data from /root/.cache/opencompass/./data/mmlu/\r\n",
      "12/18 03:27:12 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Partitioned into 1 tasks.\r\n",
      "12/18 03:27:16 - OpenCompass - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Debug mode, log will be saved to tmp/154_debug.log\r\n",
      "12/18 04:29:20 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Partitioned into 57 tasks.\r\n",
      "dataset                                            version    metric            mode      checkpoint_14000_hf\r\n",
      "-------------------------------------------------  ---------  ----------------  ------  ---------------------\r\n",
      "lukaemon_mmlu_college_biology                      0eddf6     accuracy          ppl                     21.53\r\n",
      "lukaemon_mmlu_college_chemistry                    9e2300     accuracy          ppl                     22.00\r\n",
      "lukaemon_mmlu_college_computer_science             5a1625     accuracy          ppl                     27.00\r\n",
      "lukaemon_mmlu_college_mathematics                  13e9be     accuracy          ppl                     24.00\r\n",
      "lukaemon_mmlu_college_physics                      f05705     accuracy          ppl                     20.59\r\n",
      "lukaemon_mmlu_electrical_engineering               87e5d9     accuracy          ppl                     24.14\r\n",
      "lukaemon_mmlu_astronomy                            69352a     accuracy          ppl                     26.32\r\n",
      "lukaemon_mmlu_anatomy                              a367fc     accuracy          ppl                     25.19\r\n",
      "lukaemon_mmlu_abstract_algebra                     45f14f     accuracy          ppl                     31.00\r\n",
      "lukaemon_mmlu_machine_learning                     16eb9e     accuracy          ppl                     33.93\r\n",
      "lukaemon_mmlu_clinical_knowledge                   b9517f     accuracy          ppl                     22.26\r\n",
      "lukaemon_mmlu_global_facts                         45ca5d     accuracy          ppl                     16.00\r\n",
      "lukaemon_mmlu_management                           f1f94e     accuracy          ppl                     17.48\r\n",
      "lukaemon_mmlu_nutrition                            e8c66b     accuracy          ppl                     27.12\r\n",
      "lukaemon_mmlu_marketing                            6b54fd     accuracy          ppl                     29.06\r\n",
      "lukaemon_mmlu_professional_accounting              aa502e     accuracy          ppl                     24.47\r\n",
      "lukaemon_mmlu_high_school_geography                c5312c     accuracy          ppl                     19.19\r\n",
      "lukaemon_mmlu_international_law                    c502b5     accuracy          ppl                     20.66\r\n",
      "lukaemon_mmlu_moral_scenarios                      9dab41     accuracy          ppl                     23.69\r\n",
      "lukaemon_mmlu_computer_security                    557e7e     accuracy          ppl                     22.00\r\n",
      "lukaemon_mmlu_high_school_microeconomics           9405bf     accuracy          ppl                     21.43\r\n",
      "lukaemon_mmlu_professional_law                     f36e47     accuracy          ppl                     24.77\r\n",
      "lukaemon_mmlu_medical_genetics                     038ad3     accuracy          ppl                     25.00\r\n",
      "lukaemon_mmlu_professional_psychology              429c8f     accuracy          ppl                     25.65\r\n",
      "lukaemon_mmlu_jurisprudence                        ae7f17     accuracy          ppl                     25.93\r\n",
      "lukaemon_mmlu_world_religions                      904875     accuracy          ppl                     33.33\r\n",
      "lukaemon_mmlu_philosophy                           c9014a     accuracy          ppl                     16.40\r\n",
      "lukaemon_mmlu_virology                             611723     accuracy          ppl                     25.90\r\n",
      "lukaemon_mmlu_high_school_chemistry                a25dca     accuracy          ppl                     28.57\r\n",
      "lukaemon_mmlu_public_relations                     02be4e     accuracy          ppl                     21.82\r\n",
      "lukaemon_mmlu_high_school_macroeconomics           267c80     accuracy          ppl                     20.77\r\n",
      "lukaemon_mmlu_human_sexuality                      9a9941     accuracy          ppl                     26.72\r\n",
      "lukaemon_mmlu_elementary_mathematics               197da6     accuracy          ppl                     22.75\r\n",
      "lukaemon_mmlu_high_school_physics                  777e6e     accuracy          ppl                     22.52\r\n",
      "lukaemon_mmlu_high_school_computer_science         1bae4a     accuracy          ppl                     26.00\r\n",
      "lukaemon_mmlu_high_school_european_history         ad843a     accuracy          ppl                     22.42\r\n",
      "lukaemon_mmlu_business_ethics                      83933d     accuracy          ppl                     30.00\r\n",
      "lukaemon_mmlu_moral_disputes                       2a78ed     accuracy          ppl                     24.57\r\n",
      "lukaemon_mmlu_high_school_statistics               c6e690     accuracy          ppl                     22.22\r\n",
      "lukaemon_mmlu_miscellaneous                        ab0a88     accuracy          ppl                     23.50\r\n",
      "lukaemon_mmlu_formal_logic                         fa56ca     accuracy          ppl                     30.95\r\n",
      "lukaemon_mmlu_high_school_government_and_politics  813526     accuracy          ppl                     35.23\r\n",
      "lukaemon_mmlu_prehistory                           017963     accuracy          ppl                     28.09\r\n",
      "lukaemon_mmlu_security_studies                     d60130     accuracy          ppl                     35.10\r\n",
      "lukaemon_mmlu_high_school_biology                  6f158a     accuracy          ppl                     24.52\r\n",
      "lukaemon_mmlu_logical_fallacies                    03a488     accuracy          ppl                     23.31\r\n",
      "lukaemon_mmlu_high_school_world_history            7d5f06     accuracy          ppl                     21.94\r\n",
      "lukaemon_mmlu_professional_medicine                cdcce1     accuracy          ppl                     24.63\r\n",
      "lukaemon_mmlu_high_school_mathematics              eef511     accuracy          ppl                     25.56\r\n",
      "lukaemon_mmlu_college_medicine                     21a6fb     accuracy          ppl                     21.39\r\n",
      "lukaemon_mmlu_high_school_us_history               e73ee8     accuracy          ppl                     25.49\r\n",
      "lukaemon_mmlu_sociology                            423c74     accuracy          ppl                     24.38\r\n",
      "lukaemon_mmlu_econometrics                         efcf91     accuracy          ppl                     24.56\r\n",
      "lukaemon_mmlu_high_school_psychology               971917     accuracy          ppl                     19.82\r\n",
      "lukaemon_mmlu_human_aging                          406d1b     accuracy          ppl                     21.97\r\n",
      "lukaemon_mmlu_us_foreign_policy                    ac2379     accuracy          ppl                     23.00\r\n",
      "lukaemon_mmlu_conceptual_physics                   7f414f     accuracy          ppl                     28.94\r\n",
      "mmlu-humanities                                    -          naive_average     ppl                     24.73\r\n",
      "mmlu-stem                                          -          naive_average     ppl                     25.20\r\n",
      "mmlu-social-science                                -          naive_average     ppl                     24.81\r\n",
      "mmlu-other                                         -          naive_average     ppl                     23.75\r\n",
      "mmlu                                               -          naive_average     ppl                     24.68\r\n",
      "mmlu-weighted                                      -          weighted_average  ppl                     24.45\r\n",
      "12/18 04:40:37 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - write summary to /kaggle/working/evals/sft/20241218_032709/summary/summary_20241218_032709.txt\r\n",
      "12/18 04:40:37 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - write csv to /kaggle/working/evals/sft/20241218_032709/summary/summary_20241218_032709.csv\r\n",
      "\r\n",
      "\r\n",
      "The markdown format results is as below:\r\n",
      "\r\n",
      "| dataset | version | metric | mode | checkpoint_14000_hf |\r\n",
      "|----- | ----- | ----- | ----- | -----|\r\n",
      "| lukaemon_mmlu_college_biology | 0eddf6 | accuracy | ppl | 21.53 |\r\n",
      "| lukaemon_mmlu_college_chemistry | 9e2300 | accuracy | ppl | 22.00 |\r\n",
      "| lukaemon_mmlu_college_computer_science | 5a1625 | accuracy | ppl | 27.00 |\r\n",
      "| lukaemon_mmlu_college_mathematics | 13e9be | accuracy | ppl | 24.00 |\r\n",
      "| lukaemon_mmlu_college_physics | f05705 | accuracy | ppl | 20.59 |\r\n",
      "| lukaemon_mmlu_electrical_engineering | 87e5d9 | accuracy | ppl | 24.14 |\r\n",
      "| lukaemon_mmlu_astronomy | 69352a | accuracy | ppl | 26.32 |\r\n",
      "| lukaemon_mmlu_anatomy | a367fc | accuracy | ppl | 25.19 |\r\n",
      "| lukaemon_mmlu_abstract_algebra | 45f14f | accuracy | ppl | 31.00 |\r\n",
      "| lukaemon_mmlu_machine_learning | 16eb9e | accuracy | ppl | 33.93 |\r\n",
      "| lukaemon_mmlu_clinical_knowledge | b9517f | accuracy | ppl | 22.26 |\r\n",
      "| lukaemon_mmlu_global_facts | 45ca5d | accuracy | ppl | 16.00 |\r\n",
      "| lukaemon_mmlu_management | f1f94e | accuracy | ppl | 17.48 |\r\n",
      "| lukaemon_mmlu_nutrition | e8c66b | accuracy | ppl | 27.12 |\r\n",
      "| lukaemon_mmlu_marketing | 6b54fd | accuracy | ppl | 29.06 |\r\n",
      "| lukaemon_mmlu_professional_accounting | aa502e | accuracy | ppl | 24.47 |\r\n",
      "| lukaemon_mmlu_high_school_geography | c5312c | accuracy | ppl | 19.19 |\r\n",
      "| lukaemon_mmlu_international_law | c502b5 | accuracy | ppl | 20.66 |\r\n",
      "| lukaemon_mmlu_moral_scenarios | 9dab41 | accuracy | ppl | 23.69 |\r\n",
      "| lukaemon_mmlu_computer_security | 557e7e | accuracy | ppl | 22.00 |\r\n",
      "| lukaemon_mmlu_high_school_microeconomics | 9405bf | accuracy | ppl | 21.43 |\r\n",
      "| lukaemon_mmlu_professional_law | f36e47 | accuracy | ppl | 24.77 |\r\n",
      "| lukaemon_mmlu_medical_genetics | 038ad3 | accuracy | ppl | 25.00 |\r\n",
      "| lukaemon_mmlu_professional_psychology | 429c8f | accuracy | ppl | 25.65 |\r\n",
      "| lukaemon_mmlu_jurisprudence | ae7f17 | accuracy | ppl | 25.93 |\r\n",
      "| lukaemon_mmlu_world_religions | 904875 | accuracy | ppl | 33.33 |\r\n",
      "| lukaemon_mmlu_philosophy | c9014a | accuracy | ppl | 16.40 |\r\n",
      "| lukaemon_mmlu_virology | 611723 | accuracy | ppl | 25.90 |\r\n",
      "| lukaemon_mmlu_high_school_chemistry | a25dca | accuracy | ppl | 28.57 |\r\n",
      "| lukaemon_mmlu_public_relations | 02be4e | accuracy | ppl | 21.82 |\r\n",
      "| lukaemon_mmlu_high_school_macroeconomics | 267c80 | accuracy | ppl | 20.77 |\r\n",
      "| lukaemon_mmlu_human_sexuality | 9a9941 | accuracy | ppl | 26.72 |\r\n",
      "| lukaemon_mmlu_elementary_mathematics | 197da6 | accuracy | ppl | 22.75 |\r\n",
      "| lukaemon_mmlu_high_school_physics | 777e6e | accuracy | ppl | 22.52 |\r\n",
      "| lukaemon_mmlu_high_school_computer_science | 1bae4a | accuracy | ppl | 26.00 |\r\n",
      "| lukaemon_mmlu_high_school_european_history | ad843a | accuracy | ppl | 22.42 |\r\n",
      "| lukaemon_mmlu_business_ethics | 83933d | accuracy | ppl | 30.00 |\r\n",
      "| lukaemon_mmlu_moral_disputes | 2a78ed | accuracy | ppl | 24.57 |\r\n",
      "| lukaemon_mmlu_high_school_statistics | c6e690 | accuracy | ppl | 22.22 |\r\n",
      "| lukaemon_mmlu_miscellaneous | ab0a88 | accuracy | ppl | 23.50 |\r\n",
      "| lukaemon_mmlu_formal_logic | fa56ca | accuracy | ppl | 30.95 |\r\n",
      "| lukaemon_mmlu_high_school_government_and_politics | 813526 | accuracy | ppl | 35.23 |\r\n",
      "| lukaemon_mmlu_prehistory | 017963 | accuracy | ppl | 28.09 |\r\n",
      "| lukaemon_mmlu_security_studies | d60130 | accuracy | ppl | 35.10 |\r\n",
      "| lukaemon_mmlu_high_school_biology | 6f158a | accuracy | ppl | 24.52 |\r\n",
      "| lukaemon_mmlu_logical_fallacies | 03a488 | accuracy | ppl | 23.31 |\r\n",
      "| lukaemon_mmlu_high_school_world_history | 7d5f06 | accuracy | ppl | 21.94 |\r\n",
      "| lukaemon_mmlu_professional_medicine | cdcce1 | accuracy | ppl | 24.63 |\r\n",
      "| lukaemon_mmlu_high_school_mathematics | eef511 | accuracy | ppl | 25.56 |\r\n",
      "| lukaemon_mmlu_college_medicine | 21a6fb | accuracy | ppl | 21.39 |\r\n",
      "| lukaemon_mmlu_high_school_us_history | e73ee8 | accuracy | ppl | 25.49 |\r\n",
      "| lukaemon_mmlu_sociology | 423c74 | accuracy | ppl | 24.38 |\r\n",
      "| lukaemon_mmlu_econometrics | efcf91 | accuracy | ppl | 24.56 |\r\n",
      "| lukaemon_mmlu_high_school_psychology | 971917 | accuracy | ppl | 19.82 |\r\n",
      "| lukaemon_mmlu_human_aging | 406d1b | accuracy | ppl | 21.97 |\r\n",
      "| lukaemon_mmlu_us_foreign_policy | ac2379 | accuracy | ppl | 23.00 |\r\n",
      "| lukaemon_mmlu_conceptual_physics | 7f414f | accuracy | ppl | 28.94 |\r\n",
      "| mmlu-humanities | - | naive_average | ppl | 24.73 |\r\n",
      "| mmlu-stem | - | naive_average | ppl | 25.20 |\r\n",
      "| mmlu-social-science | - | naive_average | ppl | 24.81 |\r\n",
      "| mmlu-other | - | naive_average | ppl | 23.75 |\r\n",
      "| mmlu | - | naive_average | ppl | 24.68 |\r\n",
      "| mmlu-weighted | - | weighted_average | ppl | 24.45 |\r\n",
      "\r\n",
      "12/18 04:40:37 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - write markdown summary to /kaggle/working/evals/sft/20241218_032709/summary/summary_20241218_032709.md\r\n"
     ]
    }
   ],
   "source": [
    "!cd /\n",
    "!opencompass \\\n",
    "    --datasets mmlu_ppl \\\n",
    "    --summarizer example \\\n",
    "    --hf-type base \\\n",
    "    --hf-path {SFT_MODEL_PATH} \\\n",
    "    --tokenizer-kwargs padding_side=\"left\" truncation=\"left\" \\\n",
    "    --max-seq-len 2048 \\\n",
    "    --batch-size 4 \\\n",
    "    --hf-num-gpus 2 \\\n",
    "    --work-dir \"/kaggle/working/evals/sft\" \\\n",
    "    --debug\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ec80d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/generation_config.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [00:00<00:00, 284kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/merges.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/LICENSE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7.21k/7.21k [00:00<00:00, 25.9MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/.gitattributes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1.48k/1.48k [00:00<00:00, 6.03MB/s]\n",
      "Downloading 12 files:   8%|▊         | 1/12 [00:01<00:18,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/config.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 661/661 [00:00<00:00, 1.08MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/model-00001-of-00002.safetensors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/model-00002-of-00002.safetensors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1.59M/1.59M [00:01<00:00, 1.00MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/tokenizer_config.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7.13k/7.13k [00:00<00:00, 19.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/README.md...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:00<00:00, 12.5MB/s]\n",
      "Downloading 12 files:  25%|██▌       | 3/12 [00:03<00:10,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/model.safetensors.index.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34.7k/34.7k [00:00<00:00, 180kB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/tokenizer.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/qwen-lm/qwen2.5/transformers/3b-instruct/1/download/vocab.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 2.65M/2.65M [00:04<00:00, 685kB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "100%|██████████| 6.71M/6.71M [00:06<00:00, 1.04MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 2.05G/2.05G [03:33<00:00, 10.3MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3.70G/3.70G [06:21<00:00, 10.4MB/s]\n",
      "Downloading 12 files: 100%|██████████| 12/12 [06:24<00:00, 32.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to model files: /home/xiaxinyuan/.cache/kagglehub/models/qwen-lm/qwen2.5/transformers/3b-instruct/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.model_download(\"qwen-lm/qwen2.5/transformers/3b-instruct\")\n",
    "\n",
    "print(\"Path to model files:\", path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4061777,
     "sourceId": 7056498,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6311248,
     "sourceId": 10211385,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 164048,
     "modelInstanceId": 141432,
     "sourceId": 166218,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 193943,
     "modelInstanceId": 171628,
     "sourceId": 201166,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4523.126703,
   "end_time": "2024-12-18T04:40:39.369452",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-18T03:25:16.242749",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
